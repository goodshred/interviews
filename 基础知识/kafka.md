## kafka消息堆积
Kafka 消息积压问题可能是由以下原因引起的：

1. 生产者速度过快：如果生产者的生产速度太快，超过了消费者的处理速度，就会导致消息积压。
2. 消费者处理速度慢：当消费者处理消息的速度慢于消息的生产速度时，就会导致消息积压。这可能是由消费者的性能问题、网络问题或者消费者处理消息的方式不当等原因引起的。
3. 消费者组不均衡：当消费者组中的消费者不均衡时，就会导致消息积压。例如，如果一个消费者处理速度很慢，但是它所消费的分区数量很多，就会导致消息积压。
4. 分区数量不足：当 Kafka 集群的分区数量不足时，就会导致消息积压。因为如果分区数量不足，就会导致消息堆积在同一分区，无法被及时消费。(消息实在太多，但分区又太少--加机器)

解决 Kafka 消息积压问题可以从以下几个方面入手：

1. 调整消费者的处理速度，尽量优化消费者的性能和网络环境。
2. 增加 Kafka 集群的分区数量，确保消息能够均匀地分布在不同的分区上。
3. 调整生产者的生产速度，确保生产者的生产速度与消费者的处理速度相匹配。
4. 均衡消费者组中的消费者，确保每个消费者处理的分区数量相等。

## kafka三种分区策略
轮询分区策略适合于每个分区都处理相同数量的消息的场景（默认）；哈希分区策略适合于需要保证相同 Key 值的消息被有序地处理的场景；自定义分区策略适合于需要根据业务属性或其他信息来决定消息发送到哪个分区的场景。


## kafka重复消费以及解决方案（精准一次）

需要生产者和消费者同时保证

消费者幂等性保证方案参考
[一文理解Kafka重复消费的原因和解决方案](https://cloud.tencent.com/developer/article/1839582)

**Producer升级成幂等**

kafka 0.11版本后,设置enable.idempotence = true后，Producer自动升级成幂等性Producer，其他所有的代码逻辑都不需要改变。Kafka 自动帮你做消息的重复去重。

**Producer原理**

底层具体的原理很简单，就是经典的用空间去换时间的优化思路，即在 Broker 端多保存一些字段。当Producer发送了具有相同字段值的消息后，Broker能够自动知晓这些消息已经重复了，于是可以在后台默默地把它们“丢弃”掉。

Kafka 为了实现幂等性，它在底层设计架构中引入了 ProducerID 和 SequenceNumber。

Producer 需要做的只有两件事：

1）初始化时像向 Broker 申请一个 ProducerID

2）为每条消息绑定一个 SequenceNumber

Kafka Broker 收到消息后会以 ProducerID 为单位存储 SequenceNumber，也就是说即使 Producer 重复发送了， Broker 端也会将其过滤掉。

实现比较简单，同样的限制也比较大：

首先，它只能保证单分区上的幂等性。即一个幂等性 Producer 能够保证某个主题的一个分区上不出现重复消息，它无法实现多个分区的幂等性。
因为 SequenceNumber 是以 Topic + Partition 为单位单调递增的，如果一条消息被发送到了多个分区必然会分配到不同的 SequenceNumber ,导致重复问题。
其次，它只能实现单会话上的幂等性。不能实现跨会话的幂等性。当你重启 Producer 进程之后，这种幂等性保证就丧失了。
重启 Producer 后会分配一个新的 ProducerID，相当于之前保存的 SequenceNumber 就丢失了。

## 顺序消费消息

==kafka只保证单partition有序==，如果Kafka要保证多个partition有序，不仅broker保存的数据要保持顺序，消费时也要按序消费。假设partition1堵了，为了有序，那partition2以及后续的分区也不能被消费，这种情况下，Kafka 就退化成了单一队列，毫无并发性可言，极大降低系统性能。因此Kafka使用多partition的概念，并且只保证单partition有序。这样不同partition之间不会干扰对方。

## kafka消息丢失和消息重复

消费者三种消费语义

- 至多一次:手动先commit，然后再进行消费(消息丢失)
- 至少一次:先消费，再手动commit(消息重复)
- 精准一次:(不丢不重：生产者kafka已实现，消费者需要业务自己实现)

生产者三种确认机制

- 0(丢消息)
- 1(尽可能不丢)
- -1(不丢消息）

消息丢失和消息重复的原因及现象
生产者：ack机制（尽最大可能解决消息丢失问题）+消息序列号/幂等性（解决消息重复消费：kafka已实现）

生产者：消息a发送，因为网络抖动/延迟（10s后才发送到服务器），客户端发现5s后都还没有收到服务端的ack，就判定为超时重发，这时1s就到达了服务端，写入成功，过了一会网络抖动的消息也到了---消息重复（发生意外情况的可能性是1%）----解决办法是==给消息追加序列号实现接口幂等性==

消费者：至少一次（尽最大可能解决消息丢失问题）+幂等性（解决消息重复消费：业务自己实现，比如增加消息全局唯一序列号）




## 接口幂等性

[实现接口幂等性的5种方案](https://zhuanlan.zhihu.com/p/372339784)

幂等性缺陷：会降低接口性能，增加业务复杂度，非必要不实现
幂等性优势：在于我们可以安全地重试任何幂等性操作，反正它们也不会破坏我们的系统状态。
场景
用户在APP上连续点击了多次提交订单，后台应该只产生一个订单；
向支付宝发起支付请求，由于网络问题或系统BUG重发，支付宝应该只扣一次钱。

什么情况下需要保证幂等性

以SQL为例，有下面三种场景，只有第三种场景需要开发人员使用其他策略保证幂等性：

SELECT col1 FROM tab1 WHERE col2=2，无论执行多少次都不会改变状态，是天然的幂等。
UPDATE tab1 SET col1=1 WHERE col2=2，无论执行成功多少次状态都是一致的，因此也是幂等操作。
UPDATE tab1 SET col1=col1+1 WHERE col2=2，每次执行的结果都会发生变化，这种不是幂等的。


## 布隆过滤器的原理+优缺点+使用场景+项目具体使用
[布隆过滤器的原理+优缺点+使用场景+项目具体使用](https://zhuanlan.zhihu.com/p/472935179)

## kafka幂等

#### 重复消费的场景及解决办法

# 常见问题

## xxx

至少一次：消息不丢，但可能重复
至多一次：消息会丢，但不会重复
精确一次：消息不丢，也不重复(生产者和消费者都要保证幂等)

Kafka在0.11对生产者增加了幂等性

kafka重复消费问题
说实话，使用kafka问题挺多的，重复消息至少其中一个问题
从真实业务讲解

Kafka重复消费的原因及解决方案------短链接的经典应用

kafka重复消费问题
【5秒的断电，5分钟后的rebalance】
kafka brocker上存储的消息，都有一个offset标记， kafka的消费者是通过这个标记，来维护当前已经消费的一个数据，消费者每消费一批数据呢，brocker就会更新offset的一个值，避免重复消费的一个问题，默认情况下消息消费完成以后，会自动提交offset这样一个值，避免重复消费，消费端的这个自动提交机制会有一个五秒的间隔，5秒之后的下一次向broker去获取消息的时候，来实现一个offset提交，所以在consumer的消费过程中，应用程序强制被kill掉或者宕机的过程， 可能会导致offset没有提交，从而产生重复消费的一个问题，除此之外，还有另外一种情况也会导致重复消费

有一个叫partition balance的一个机制，就是把多个partition均衡的分配给多个消费者，comsumer端会从分配的partition里面去消费消息，如果comsumer在默认的五分钟内，没办法，处理完这一批消息的时候，就会触发kafka的rebalance机制，从而导致offset自动提交失败，而在重新rebalance以后，comsumer端还是会从之前的没有提交的offset的位置，开始去消费，从而导致重复消费的问题。在这样的背景下，解决重复消费的方法有

1.提高消费端的处理性能，避免触发rebalance(可以用异步的方式处理消息，缩短单个消息的消费时长)，
2.调整消费端消息处理的一个超时时间(把它拉长一点)
3.减少一次性从broker上获取消息的条数
4.针对每个消息生成一个md 5的值保存到mysql或者redis中，在处理消息之前，先去数据库中查看是否有被消费过(该方法其实就是利用幂等性的思想去实现的)
重复消费的问题，如果没有考虑到，就会出现线上数据问题

为什么五分钟没有消费完消息就会触发rebance:
kafka的批量提交机制，默认5分钟下游端要消费500条数据，如果消费不到，kafka会认为你的consumer已经死了，然后会从批量提交过的位置rebalance，就是重新发一遍消息到consumer，原始的数据也不会清除，这就导致重复消费，这个问题我在生产环境遇到过，所以重逻辑处理用Kafka真是坑到家了

:很简单，将时间间隔设长或者消费条数变少，或者关闭自动提交，手动ack就行
————————————————
版权声明：本文为CSDN博主「千篇不一律」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。
原文链接：https://blog.csdn.net/qq_41063141/article/details/126650668

## 参考

[接口幂等性](https://zhuanlan.zhihu.com/p/372339784)
[Kafka(Go)教程(十)---Kafka 是如何实现精确一次（exactly once）语义的？](https://blog.csdn.net/java_1996/article/details/121177112)
[一文理解如何实现接口的幂等性](https://mp.weixin.qq.com/s?__biz=MzUyNzgyNzAwNg==&mid=2247484349&idx=1&sn=b54c0819bc100db816cda52d11476401&scene=21#wechat_redirect)
[一文理解Kafka重复消费的原因和解决方案](https://cloud.tencent.com/developer/article/1839582)
