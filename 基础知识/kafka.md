## kafka重复消费以及解决方案（精准一次）

需要生产者和消费者同时保证

消费者幂等性保证方案参考
[一文理解Kafka重复消费的原因和解决方案](https://cloud.tencent.com/developer/article/1839582)

**Producer升级成幂等**

kafka 0.11版本后,设置enable.idempotence = true后，Producer自动升级成幂等性Producer，其他所有的代码逻辑都不需要改变。Kafka 自动帮你做消息的重复去重。

**Producer原理**

底层具体的原理很简单，就是经典的用空间去换时间的优化思路，即在 Broker 端多保存一些字段。当Producer发送了具有相同字段值的消息后，Broker能够自动知晓这些消息已经重复了，于是可以在后台默默地把它们“丢弃”掉。

Kafka 为了实现幂等性，它在底层设计架构中引入了 ProducerID 和 SequenceNumber。

Producer 需要做的只有两件事：

1）初始化时像向 Broker 申请一个 ProducerID

2）为每条消息绑定一个 SequenceNumber

Kafka Broker 收到消息后会以 ProducerID 为单位存储 SequenceNumber，也就是说即使 Producer 重复发送了， Broker 端也会将其过滤掉。

实现比较简单，同样的限制也比较大：

首先，它只能保证单分区上的幂等性。即一个幂等性 Producer 能够保证某个主题的一个分区上不出现重复消息，它无法实现多个分区的幂等性。
因为 SequenceNumber 是以 Topic + Partition 为单位单调递增的，如果一条消息被发送到了多个分区必然会分配到不同的 SequenceNumber ,导致重复问题。
其次，它只能实现单会话上的幂等性。不能实现跨会话的幂等性。当你重启 Producer 进程之后，这种幂等性保证就丧失了。
重启 Producer 后会分配一个新的 ProducerID，相当于之前保存的 SequenceNumber 就丢失了。

## 顺序消费消息

==kafka只保证单partition有序==，如果Kafka要保证多个partition有序，不仅broker保存的数据要保持顺序，消费时也要按序消费。假设partition1堵了，为了有序，那partition2以及后续的分区也不能被消费，这种情况下，Kafka 就退化成了单一队列，毫无并发性可言，极大降低系统性能。因此Kafka使用多partition的概念，并且只保证单partition有序。这样不同partition之间不会干扰对方。

## kafka消息丢失和消息重复

消费者三种消费语义

- 至多一次:手动先commit，然后再进行消费(消息丢失)
- 至少一次:先消费，再手动commit(消息重复)
- 精准一次:(不丢不重：生产者kafka已实现，消费者需要业务自己实现)

生产者三种确认机制

- 0(丢消息)
- 1(尽可能不丢)
- -1(不丢消息）

消息丢失和消息重复的原因及现象
生产者：ack机制（尽最大可能解决消息丢失问题）+消息序列号/幂等性（解决消息重复消费：kafka已实现）

生产者：消息a发送，因为网络抖动/延迟（10s后才发送到服务器），客户端发现5s后都还没有收到服务端的ack，就判定为超时重发，这时1s就到达了服务端，写入成功，过了一会网络抖动的消息也到了---消息重复（发生意外情况的可能性是1%）----解决办法是==给消息追加序列号实现接口幂等性==

消费者：至少一次（尽最大可能解决消息丢失问题）+幂等性（解决消息重复消费：业务自己实现，比如增加消息全局唯一序列号）

## kafka消息堆积

https://www.bilibili.com/video/BV1Zd4y1T7Se/?spm_id_from=333.337.search-card.all.click

https://www.cnblogs.com/kebibuluan/p/15933739.html



消息堆积原因
消息堆积发生的常见原因有以下情况：

生产者短期间生产大量消息到Broker, 消费者无法及时消费（消费者并发低）；
生产者无法感知消息堆积，持续生产消息，导致消息堆积进一步加剧
消费者能力不足，消费时间长，消费者宕机、网络异常与Broker无法通信
分区设置异常
新上线消费者功能存在bug,无法消费消息

总结以上
解决方案
从主要消息堆积原因来看，主要分为这几个类型，消费者端，生产者端，服务端；

消费者端


增加消费者实例个数，并发消费线程数量
提高消费者消费的速度，避免消费消息时间过长。如果消费者处理慢，可以提高每批次拉取的数量。批次拉取数量过少（拉取数据/处理时间 < 生产速度），就容易堆积。
消费kafka消息时，应该尽量减少每次消费时间，可通过减少调用三方接口、读库等操作， 从而减少消息堆积的可能性。
增加消费组服务数量，合理增加 topic 的 partition 的个数 ，消费数 >= 分区数 （二者缺一不可）
消息者支持灰度发布
配置消费者参数，任务启动从上次提交offset处开始消费处理
如果确实容易出现堆积，消息来不及消费，建议可以先存在数据库中，然后逐条消费，不仅方便重新触发生产消息，还可以保留消费记录）


生产者端


支持熔断与隔离， 当broker消息堆积时，对生产者能进行熔断，或将生产的消息先发送到其他topic
设计时，Kafka消息key设置,给key加随机后缀，使其更均衡


服务端



合理设置parition很重要，Kafka parition数是Kafka并行度调优的最小单元，如果Kafka分区数设置的太少，会直接影响Kafka consumer消费的吞吐量


生产环境kafka必须集群， 有条件的支持异地多活，应对极端情况


需要注意kafka消息保留时间（修改kafka配置文件， 默认一周）


合理设置parition很重要，且看下篇。


## 接口幂等性

[实现接口幂等性的5种方案](https://zhuanlan.zhihu.com/p/372339784)

幂等性缺陷：会降低接口性能，增加业务复杂度，非必要不实现
幂等性优势：在于我们可以安全地重试任何幂等性操作，反正它们也不会破坏我们的系统状态。
场景
用户在APP上连续点击了多次提交订单，后台应该只产生一个订单；
向支付宝发起支付请求，由于网络问题或系统BUG重发，支付宝应该只扣一次钱。

什么情况下需要保证幂等性

以SQL为例，有下面三种场景，只有第三种场景需要开发人员使用其他策略保证幂等性：

SELECT col1 FROM tab1 WHERE col2=2，无论执行多少次都不会改变状态，是天然的幂等。
UPDATE tab1 SET col1=1 WHERE col2=2，无论执行成功多少次状态都是一致的，因此也是幂等操作。
UPDATE tab1 SET col1=col1+1 WHERE col2=2，每次执行的结果都会发生变化，这种不是幂等的。


## 布隆过滤器的原理+优缺点+使用场景+项目具体使用
[布隆过滤器的原理+优缺点+使用场景+项目具体使用](https://zhuanlan.zhihu.com/p/472935179)

## kafka幂等

#### 重复消费的场景及解决办法

# 常见问题

## xxx

至少一次：消息不丢，但可能重复
至多一次：消息会丢，但不会重复
精确一次：消息不丢，也不重复(生产者和消费者都要保证幂等)

Kafka在0.11对生产者增加了幂等性

kafka重复消费问题
说实话，使用kafka问题挺多的，重复消息至少其中一个问题
从真实业务讲解

Kafka重复消费的原因及解决方案------短链接的经典应用

kafka重复消费问题
【5秒的断电，5分钟后的rebalance】
kafka brocker上存储的消息，都有一个offset标记， kafka的消费者是通过这个标记，来维护当前已经消费的一个数据，消费者每消费一批数据呢，brocker就会更新offset的一个值，避免重复消费的一个问题，默认情况下消息消费完成以后，会自动提交offset这样一个值，避免重复消费，消费端的这个自动提交机制会有一个五秒的间隔，5秒之后的下一次向broker去获取消息的时候，来实现一个offset提交，所以在consumer的消费过程中，应用程序强制被kill掉或者宕机的过程， 可能会导致offset没有提交，从而产生重复消费的一个问题，除此之外，还有另外一种情况也会导致重复消费

有一个叫partition balance的一个机制，就是把多个partition均衡的分配给多个消费者，comsumer端会从分配的partition里面去消费消息，如果comsumer在默认的五分钟内，没办法，处理完这一批消息的时候，就会触发kafka的rebalance机制，从而导致offset自动提交失败，而在重新rebalance以后，comsumer端还是会从之前的没有提交的offset的位置，开始去消费，从而导致重复消费的问题。在这样的背景下，解决重复消费的方法有

1.提高消费端的处理性能，避免触发rebalance(可以用异步的方式处理消息，缩短单个消息的消费时长)，
2.调整消费端消息处理的一个超时时间(把它拉长一点)
3.减少一次性从broker上获取消息的条数
4.针对每个消息生成一个md 5的值保存到mysql或者redis中，在处理消息之前，先去数据库中查看是否有被消费过(该方法其实就是利用幂等性的思想去实现的)
重复消费的问题，如果没有考虑到，就会出现线上数据问题

为什么五分钟没有消费完消息就会触发rebance:
kafka的批量提交机制，默认5分钟下游端要消费500条数据，如果消费不到，kafka会认为你的consumer已经死了，然后会从批量提交过的位置rebalance，就是重新发一遍消息到consumer，原始的数据也不会清除，这就导致重复消费，这个问题我在生产环境遇到过，所以重逻辑处理用Kafka真是坑到家了

:很简单，将时间间隔设长或者消费条数变少，或者关闭自动提交，手动ack就行
————————————————
版权声明：本文为CSDN博主「千篇不一律」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。
原文链接：https://blog.csdn.net/qq_41063141/article/details/126650668

## 参考

[接口幂等性](https://zhuanlan.zhihu.com/p/372339784)
[Kafka(Go)教程(十)---Kafka 是如何实现精确一次（exactly once）语义的？](https://blog.csdn.net/java_1996/article/details/121177112)
[一文理解如何实现接口的幂等性](https://mp.weixin.qq.com/s?__biz=MzUyNzgyNzAwNg==&mid=2247484349&idx=1&sn=b54c0819bc100db816cda52d11476401&scene=21#wechat_redirect)
[一文理解Kafka重复消费的原因和解决方案](https://cloud.tencent.com/developer/article/1839582)
